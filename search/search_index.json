{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"docstring-gen","text":"<p>Instantly improve the documentation of your Python code with Codex.</p> <p> </p> <p> </p> <p></p> <p>docstring-gen is an easy-to-use Python library that uses OpenAI\u2019s Codex model to automatically generate Google-style docstrings for Python codebase. The library is capable of reading both Jupyter notebooks and Python files, and seamlessly adds meaningful docstrings to classes and functions that lack documentation. By using docstring-gen, developers can automatically generate docstrings for their codebase, resulting in time savings and improved documentation quality.</p>"},{"location":"#install","title":"Install","text":"<p>docstring-gen can be installed by running the command below. This package requires Python 3.7 or higher to work.</p> <pre><code>pip install docstring-gen\n</code></pre> <p>If the installation was successful, you should now have docstring-gen installed on your system. To see a full list of settings, run <code>docstring_gen --help</code></p> <p>If you\u2019re excited to try the latest version, you can install it directly from GitHub by using the command: <code>pip install git+https://github.com/airtai/docstring-gen</code></p>"},{"location":"#how-to-use","title":"How to use","text":"<p>The docstring-gen library uses OpenAI\u2019s Codex model to generate docstrings for your Python classes and functions. In order to use the library, you\u2019ll need to create an API key for OpenAI.</p> <p>Once you have your API key, store it in the OPENAI_API_KEY environment variable. This is a necessary step for the library to work.</p> <p>To get started right away with sensible defaults, run:</p> <pre><code>docstring_gen {source_file_or_directory}\n</code></pre> <p>This will automatically add meaningful, Google-style docstrings to the Python classes and functions in the {source_file_or_directory} that do not already have one.</p> <p>For example, a function like below without the docstring:</p> <pre><code>def concatenate_strings(s1: str, s2: str) -&gt; str:\n    if not isinstance(s1, str) or not isinstance(s2, str):\n        raise TypeError(\"Both arguments should be strings.\")\n    return s1 + s2\n</code></pre> <p>will become similar to:</p> <pre><code>def concatenate_strings(s1: str, s2: str) -&gt; str:\n\"\"\"Concatenate two strings.\n\n    Args:\n        s1: First string\n        s2: Second string\n\n    Returns:\n        The concatenated string\n\n    Raises:\n        TypeError: If s1 or s2 is not a string\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    if not isinstance(s1, str) or not isinstance(s2, str):\n        raise TypeError(\"Both arguments should be strings.\")\n    return s1 + s2\n</code></pre> <p>If you wish to regenerate the docstrings, you can re-run the command with the <code>-f</code> flag, which will remove the previous auto-generated docstrings and replace them with new ones.</p> <pre><code>docstring_gen {source_file_or_directory} -f\n</code></pre> <p>Note: The default behavior of the library is to add docstrings only to functions and classes that are missing them. So, if you do not provide the <code>-f</code> flag when re-running the command, the library will not replace previously auto-generated docstrings, assuming that the functions already have them.</p> <p>If you prefer not to include the text \u201cautogenerated by docstring-gen library\u201d in the generated docstrings, you can use the <code>--no-include-auto-gen-txt</code> flag when running the command.</p> <pre><code>docstring_gen {source_file_or_directory} -f --no-include-auto-gen-txt\n</code></pre> <p>Now the docstring for the above function will look similar to:</p> <pre><code>def concatenate_strings(s1: str, s2: str) -&gt; str:\n\"\"\"Concatenate two strings.\n\n    Args:\n        s1: First string\n        s2: Second string\n\n    Returns:\n        The concatenated string\n\n    Raises:\n        TypeError: If s1 or s2 is not a string\n    \"\"\"\n    if not isinstance(s1, str) or not isinstance(s2, str):\n        raise TypeError(\"Both arguments should be strings.\")\n    return s1 + s2\n</code></pre> <p>Important: The library uses the text \u201cautogenerated by docstring-gen library\u201d to identify which docstrings were generated by the library. When the <code>--no-include-auto-gen-txt</code> flag is used, this text will not be included in the generated docstrings. As a result, when re-running the command with the <code>-f</code> flag, these docstrings will not be replaced.\u201d</p> <p>Alternatively, you can manually delete the \u201cautogenerated by docstring-gen library\u201d (starting from the !!! note until the end) text from the classes and functions for which you think the auto-generated docstring is appropriate, and then re-run the command using the <code>-f</code> flag to update the remaining auto-generated docstrings.</p> <p>In addition to the <code>-f</code> and <code>--no-include-auto-gen-txt</code> flags, you can also customize the behavior by adjusting other parameters such as <code>--model</code>, <code>--temperature</code>, etc., For more information on these options and how to use them, please refer to the OpenAI\u2019s documentation.</p>"},{"location":"#jupyter-notebook-extension","title":"Jupyter notebook extension","text":"<p>We have created a user-friendly notebook extension for the docstring-gen library. This extension provides a convenient way to document your code cell-by-cell, rather than having to document the entire notebook all at once. To install the extension, simply run the following commands in your terminal:</p> <p>Note: Please ensure jupyter-contrib-nbextensions. is installed before installing the docstring-gen library extension</p> <pre><code>jupyter nbextension install https://github.com/airtai/jupyter-docstring-gen/archive/main.zip --user\njupyter nbextension enable jupyter-docstring-gen-main/jupyter-docstring-gen\n</code></pre> <p>After successful installation, you will see a new button on your jupyter notebook toolbar. This button allows you to easily generate docstrings for your Python code and improve your documentation.</p> <p></p> <p>For more detailed information, please refer to this link.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright \u00a9 2023 onwards airt technologies ltd, Inc.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the Apache License 2.0</p>"},{"location":"CHANGELOG/","title":"Release notes","text":""},{"location":"CHANGELOG/#040","title":"0.4.0","text":""},{"location":"CHANGELOG/#040_1","title":"0.4.0","text":""},{"location":"CHANGELOG/#new-features","title":"New Features","text":"<ul> <li>Support for Python 3.7 has been removed.</li> </ul>"},{"location":"CHANGELOG/#bugs-squashed","title":"Bugs Squashed","text":"<ul> <li>AttributeError: module 'openai' has no attribute 'error (#212)</li> </ul>"},{"location":"CHANGELOG/#030","title":"0.3.0","text":""},{"location":"CHANGELOG/#new-features_1","title":"New Features","text":"<ul> <li>Add broken link checker CI action file (#24), thanks to @harishmohanraj</li> <li> <p>Closes #23</p> </li> <li> <p>Add broken link checker CI action file (#23)</p> </li> <li> <p>Install the GitHooks in docstring-gen (#7)</p> </li> <li> <p>Hooks should have an option to setup all or individual hooks below</p> <ul> <li> nbqa-black</li> <li> mypy</li> <li> bandid</li> <li> semgrep</li> </ul> </li> <li> <p>Create notebook toolbar button for generating docstring (#3)</p> </li> </ul>"},{"location":"CHANGELOG/#bugs-squashed_1","title":"Bugs Squashed","text":"<ul> <li> <p>Switch to chatGPT model from codex model (#25)</p> </li> <li> <p>url of pages for docstring-gen docs reverts to github (#19)</p> </li> </ul>"},{"location":"CHANGELOG/#022","title":"0.2.2","text":"<ul> <li>Documentation polishing</li> </ul>"},{"location":"CHANGELOG/#020","title":"0.2.0","text":""},{"location":"CHANGELOG/#new-features_2","title":"New Features","text":"<ul> <li> <p>Enable Google Analytics (#6)</p> </li> <li> <p>Add CNAME file (#5)</p> </li> </ul>"},{"location":"CHANGELOG/#bugs-squashed_2","title":"Bugs Squashed","text":"<ul> <li>Handle exceptions and print the names of failed files in the console (#13)</li> </ul>"},{"location":"CHANGELOG/#020_1","title":"0.2.0","text":""},{"location":"CHANGELOG/#new-features_3","title":"New Features","text":"<ul> <li> <p>Enable Google Analytics (#6)</p> </li> <li> <p>Add CNAME file (#5)</p> </li> </ul>"},{"location":"CHANGELOG/#bugs-squashed_3","title":"Bugs Squashed","text":"<ul> <li>Handle exceptions and print the names of failed files in the console (#13)</li> </ul>"},{"location":"CHANGELOG/#010","title":"0.1.0","text":"<p>Initial release</p>"},{"location":"CLI/","title":"CLI","text":"<pre><code>from typer.testing import CliRunner\n</code></pre> <pre><code>runner = CliRunner()\n</code></pre>"},{"location":"CLI/#gen","title":"gen","text":"<pre><code> gen (path:str=&lt;typer.models.ArgumentInfo object at 0x7f1d852a4700&gt;,\n      include_auto_gen_txt:bool=&lt;typer.models.OptionInfo object at\n      0x7f1d852a46d0&gt;,\n      recreate_auto_gen_docs:bool=&lt;typer.models.OptionInfo object at\n      0x7f1d852dc760&gt;, model:str=&lt;typer.models.OptionInfo object at\n      0x7f1d852dc790&gt;, temperature:float=&lt;typer.models.OptionInfo object\n      at 0x7f1d852dc730&gt;, max_tokens:int=&lt;typer.models.OptionInfo object\n      at 0x7f1d852dc6d0&gt;, top_p:float=&lt;typer.models.OptionInfo object at\n      0x7f1d852dc700&gt;, n:int=&lt;typer.models.OptionInfo object at\n      0x7f1d852dc7c0&gt;)\n</code></pre> <pre><code>result = runner.invoke(_app, [\"--help\"])\n</code></pre> <pre>                                                                                                                   Usage: gen [OPTIONS] [PATH]                                                                                       \n</pre> <pre> This command reads a Jupyter notebook or Python file, or a directory containing these files, and adds docstrings  \n to classes and methods that do not have them.                                                                     \n                                                                                                                   \n</pre> <pre>\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502   path      [PATH]  The path to the Jupyter notebook or Python file, or a directory containing these files      \u2502\n\u2502                     [default: .]                                                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre>\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --include-auto-gen-txt         --no-include-auto-gen-t\u2026      If set to True, a note    \u2502\n\u2502                                                                                       indicating that the       \u2502\n\u2502                                                                                       docstring was             \u2502\n\u2502                                                                                       autogenerated by          \u2502\n\u2502                                                                                       docstring-gen library     \u2502\n\u2502                                                                                       will be added to the end. \u2502\n\u2502                                                                                       [default:                 \u2502\n\u2502                                                                                       include-auto-gen-txt]     \u2502\n\u2502 --force-recreate-auto-ge\u2026  -f                                If set to True, the       \u2502\n\u2502                                                                                       autogenerated docstrings  \u2502\n\u2502                                                                                       from the previous runs    \u2502\n\u2502                                                                                       will be replaced with the \u2502\n\u2502                                                                                       new one.                  \u2502\n\u2502 --model                                                    TEXT                       The name of the GPT model \u2502\n\u2502                                                                                       that will be used to      \u2502\n\u2502                                                                                       generate docstrings.      \u2502\n\u2502                                                                                       [default: gpt-3.5-turbo]  \u2502\n\u2502 --temperature                                              FLOAT RANGE [0.0&lt;=x&lt;=2.0]  Setting the temperature   \u2502\n\u2502                                                                                       close to zero produces    \u2502\n\u2502                                                                                       better results, whereas   \u2502\n\u2502                                                                                       higher temperatures       \u2502\n\u2502                                                                                       produce more complex, and \u2502\n\u2502                                                                                       sometimes irrelevant      \u2502\n\u2502                                                                                       docstrings.               \u2502\n\u2502                                                                                       [default: 0.2]            \u2502\n\u2502 --max-tokens                                               INTEGER                    The maximum number of     \u2502\n\u2502                                                                                       tokens to be used when    \u2502\n\u2502                                                                                       generating a docstring    \u2502\n\u2502                                                                                       for a function or class.  \u2502\n\u2502                                                                                       Please note that a higher \u2502\n\u2502                                                                                       number will deplete your  \u2502\n\u2502                                                                                       token quota faster.       \u2502\n\u2502                                                                                       [default: 250]            \u2502\n\u2502 --top-p                                                    FLOAT RANGE [0.0&lt;=x&lt;=1.0]  You can also specify a    \u2502\n\u2502                                                                                       top-P value from 0-1 to   \u2502\n\u2502                                                                                       achieve similar results   \u2502\n\u2502                                                                                       to changing the           \u2502\n\u2502                                                                                       temperature. According to \u2502\n\u2502                                                                                       the Open AI               \u2502\n\u2502                                                                                       documentation, it is      \u2502\n\u2502                                                                                       generally recommended to  \u2502\n\u2502                                                                                       change either this or the \u2502\n\u2502                                                                                       temperature but not both. \u2502\n\u2502                                                                                       [default: 1.0]            \u2502\n\u2502 --n                                                        INTEGER                    The number of docstrings  \u2502\n\u2502                                                                                       to be generated for each  \u2502\n\u2502                                                                                       function or class, with   \u2502\n\u2502                                                                                       the best one being added  \u2502\n\u2502                                                                                       to the source code.       \u2502\n\u2502                                                                                       Please note that a higher \u2502\n\u2502                                                                                       number will deplete your  \u2502\n\u2502                                                                                       token quota faster.       \u2502\n\u2502                                                                                       [default: 3]              \u2502\n\u2502 --install-completion                                         Install completion for    \u2502\n\u2502                                                                                       the current shell.        \u2502\n\u2502 --show-completion                                            Show completion for the   \u2502\n\u2502                                                                                       current shell, to copy it \u2502\n\u2502                                                                                       or customize the          \u2502\n\u2502                                                                                       installation.             \u2502\n\u2502 --help                                                       Show this message and     \u2502\n\u2502                                                                                       exit.                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre>"},{"location":"Docstring_Generator/","title":"Docstring Generator","text":"<pre><code>import shutil\nfrom tempfile import TemporaryDirectory\nfrom contextlib import contextmanager\nimport unittest.mock\n\nimport pytest\n</code></pre> <pre><code>source = \"\"\"\nclass Test:\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        self.a = a\n\n    async def drive(self):\n\n\n        print(f'The {self.model} is now driving.')\n\n    def func_with_docstring():\n\\\"\"\" Sample docstring\\\"\"\"\n        pass\n\ndef _check_and_add_docstrings_to_source(\n    source: str, include_auto_gen_txt: bool, **kwargs\n) -&gt; str:\n    source = _remove_auto_generated_docstring(source)    \n    tree = ast.parse(source)\n    line_offset = 0\n\n    for node in tree.body:\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n            continue\n\n        if ast.get_docstring(node) is not None:\n            continue\n\n        source, line_offset = _add_docstring(\n            source, node, line_offset, include_auto_gen_txt, **kwargs\n        )\n        if not isinstance(node, ast.ClassDef):\n            continue\n        # Is a class and we need to check the functions inside\n        # 29 - 36 make it as a recursive function\n        for f in node.body:\n            if not isinstance(f, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                continue\n\n            if ast.get_docstring(f) is not None:\n                continue\n\n            # should be a function inside the class for which there is no docstring\n            source, line_offset = _add_docstring(\n                source, f, line_offset, include_auto_gen_txt, **kwargs\n            )\n\n    return source\n\ndef test_callback(tree, source, start_lineno, end_lineno):\n\\\"\"\"Prints the source code of the given node\n\n    Args:\n        tree: The AST tree\n        source: The source code\n        start_lineno: The start line number\n        end_lineno: The end line number\n\\\"\"\"\n\n    pass\n\"\"\"\ntest_callback = unittest.mock.MagicMock()\ntree = ast.parse(source)\n\n_visit_functions(tree, source=source, callback=test_callback)\n\nactual = [\n    (start_lineno, end_lineno)\n    for tree, source, start_lineno, end_lineno in [\n        x[1] for x in test_callback.mock_calls\n    ]\n]\nexpected = [(2, 16), (5, 7), (8, 12), (17, 51)]\n\nprint(actual)\nassert actual == expected, actual\n</code></pre> <pre><code>[(2, 16), (5, 7), (8, 12), (17, 51)]\n</code></pre> <pre><code>source_with_dosctring = '''\nclass Test:\n    \"\"\" Sample docstring\"\"\"\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        \"\"\" Sample docstring\"\"\"\n        self.a = a\n\n    async def drive(self):\n        \"\"\" Sample docstring\"\"\"\n        print(f'The {self.model} is now driving.')\n\n    def func_with_docstring():\n        \"\"\" Sample docstring\"\"\"\n        pass\n'''\ntest_callback = unittest.mock.MagicMock()\ntree = ast.parse(source_with_dosctring)\n\n_visit_functions(tree, source=source_with_dosctring, callback=test_callback)\n\nactual = [\n    (start_lineno, end_lineno)\n    for tree, source, start_lineno, end_lineno in [\n        x[1] for x in test_callback.mock_calls\n    ]\n]\nexpected = []\n\nprint(actual)\nassert actual == expected, actual\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>def test_callback(tree, source, start_lineno, end_lineno):\n\"\"\"Prints the source code of the given node\n\n    Args:\n        tree: The AST tree\n        source: The source code\n        start_lineno: The start line number\n        end_lineno: The end line number\n\n    \"\"\"\n\n    source_lines = source.split(\"\\n\")\n    node_lines = source_lines[start_lineno - 1 : end_lineno]\n    print(\"*\" * 120)\n    print(\"\\n\".join(node_lines))\n\n\ntree = ast.parse(source)\n\n_visit_functions(tree, source=source, callback=test_callback)\n</code></pre> <pre><code>************************************************************************************************************************\nclass Test:\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        self.a = a\n\n    async def drive(self):\n\n\n        print(f'The {self.model} is now driving.')\n\n    def func_with_docstring():\n        \"\"\" Sample docstring\"\"\"\n        pass\n\n************************************************************************************************************************\n    def __init__(self, a):\n        self.a = a\n\n************************************************************************************************************************\n    async def drive(self):\n\n\n        print(f'The {self.model} is now driving.')\n\n************************************************************************************************************************\ndef _check_and_add_docstrings_to_source(\n    source: str, include_auto_gen_txt: bool, **kwargs\n) -&gt; str:\n    source = _remove_auto_generated_docstring(source)    \n    tree = ast.parse(source)\n    line_offset = 0\n\n    for node in tree.body:\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n            continue\n\n        if ast.get_docstring(node) is not None:\n            continue\n\n        source, line_offset = _add_docstring(\n            source, node, line_offset, include_auto_gen_txt, **kwargs\n        )\n        if not isinstance(node, ast.ClassDef):\n            continue\n        # Is a class and we need to check the functions inside\n        # 29 - 36 make it as a recursive function\n        for f in node.body:\n            if not isinstance(f, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                continue\n\n            if ast.get_docstring(f) is not None:\n                continue\n\n            # should be a function inside the class for which there is no docstring\n            source, line_offset = _add_docstring(\n                source, f, line_offset, include_auto_gen_txt, **kwargs\n            )\n\n    return source\n</code></pre> <pre><code>actual = _get_classes_and_functions(source)\nexpected = [(2, 2, 16, 4), (5, 5, 7, 8), (8, 10, 12, 8), (17, 19, 51, 4)]\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>[(2, 2, 16, 4), (5, 5, 7, 8), (8, 10, 12, 8), (17, 19, 51, 4)]\n</code></pre> <pre><code>linenos = _get_classes_and_functions(source)\nprint(linenos)\nactual = [\n    _get_code_from_source(source, start_line_no, end_line_no)\n    for start_line_no, docstring_line_no, end_line_no, node_offset in linenos\n]\nexpected = [\n    'class Test:\\n    CONST_VAL = 1\\n    \\n    def __init__(self, a):\\n        self.a = a\\n        \\n    async def drive(self):\\n    \\n    \\n        print(f\\'The {self.model} is now driving.\\')\\n        \\n    def func_with_docstring():\\n        \"\"\" Sample docstring\"\"\"\\n        pass\\n        ',\n    \"    def __init__(self, a):\\n        self.a = a\\n        \",\n    \"    async def drive(self):\\n    \\n    \\n        print(f'The {self.model} is now driving.')\\n        \",\n    \"def _check_and_add_docstrings_to_source(\\n    source: str, include_auto_gen_txt: bool, **kwargs\\n) -&gt; str:\\n    source = _remove_auto_generated_docstring(source)    \\n    tree = ast.parse(source)\\n    line_offset = 0\\n\\n    for node in tree.body:\\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\\n            continue\\n        \\n        if ast.get_docstring(node) is not None:\\n            continue\\n\\n        source, line_offset = _add_docstring(\\n            source, node, line_offset, include_auto_gen_txt, **kwargs\\n        )\\n        if not isinstance(node, ast.ClassDef):\\n            continue\\n        # Is a class and we need to check the functions inside\\n        # 29 - 36 make it as a recursive function\\n        for f in node.body:\\n            if not isinstance(f, (ast.FunctionDef, ast.AsyncFunctionDef)):\\n                continue\\n            \\n            if ast.get_docstring(f) is not None:\\n                continue\\n\\n            # should be a function inside the class for which there is no docstring\\n            source, line_offset = _add_docstring(\\n                source, f, line_offset, include_auto_gen_txt, **kwargs\\n            )\\n\\n    return source\\n    \",\n]\nfor f in actual:\n    print(\"*\" * 100)\n    print(f)\n\nassert actual == expected\n</code></pre> <pre><code>[(2, 2, 16, 4), (5, 5, 7, 8), (8, 10, 12, 8), (17, 19, 51, 4)]\n****************************************************************************************************\nclass Test:\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        self.a = a\n\n    async def drive(self):\n\n\n        print(f'The {self.model} is now driving.')\n\n    def func_with_docstring():\n        \"\"\" Sample docstring\"\"\"\n        pass\n\n****************************************************************************************************\n    def __init__(self, a):\n        self.a = a\n\n****************************************************************************************************\n    async def drive(self):\n\n\n        print(f'The {self.model} is now driving.')\n\n****************************************************************************************************\ndef _check_and_add_docstrings_to_source(\n    source: str, include_auto_gen_txt: bool, **kwargs\n) -&gt; str:\n    source = _remove_auto_generated_docstring(source)    \n    tree = ast.parse(source)\n    line_offset = 0\n\n    for node in tree.body:\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n            continue\n\n        if ast.get_docstring(node) is not None:\n            continue\n\n        source, line_offset = _add_docstring(\n            source, node, line_offset, include_auto_gen_txt, **kwargs\n        )\n        if not isinstance(node, ast.ClassDef):\n            continue\n        # Is a class and we need to check the functions inside\n        # 29 - 36 make it as a recursive function\n        for f in node.body:\n            if not isinstance(f, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                continue\n\n            if ast.get_docstring(f) is not None:\n                continue\n\n            # should be a function inside the class for which there is no docstring\n            source, line_offset = _add_docstring(\n                source, f, line_offset, include_auto_gen_txt, **kwargs\n            )\n\n    return source\n</code></pre> <pre><code>print(DEFAULT_MESSAGE_TEMPLATE)\nassert DEFAULT_MESSAGE_TEMPLATE[0] == SYSTEM_INSTRUCTION\nassert DEFAULT_MESSAGE_TEMPLATE[1:] == FEW_SHOT_EXAMPLES\n</code></pre> <pre><code>[{'role': 'system', 'content': 'You are an assistant designed read Python code and write comprehensive Google styled docstrings for Python Classes and functions. Users will paste python code and you will respond with a high quality comprehensive docstring using the following procedure:\\n\\n(1) First, classify whether the given code is a Python Class or a Function\\n(2) Second, for python Classes, you must format your docstring in the below format. Never ever break this rule and do not add additional information\\n\"\"\"One line summary of class here.\\n\\nAtttibutes:\\n\"\"\"\\n(3) Third, for python functions, you must format your docstring as per the Google Python Style Guide.'}, {'role': 'user', 'content': '\\ndef add_strings(s1: Optional[str] = None, s2: Optional[str] = None) -&gt; str:\\n    if s1 is None or s2 is None:\\n        raise ValueError(Both s1 and s2 must be provided and must be of type string\")\\n    return s1 + s2\\n        '}, {'role': 'assistant', 'content': 'Add two strings\\n\\nArgs:\\n    s1: First string\\n    s2: Second string\\n    \\nReturns:\\n    The added string\\n    \\nRaises:\\n    ValueError: If s1 or s2 is None\\n'}, {'role': 'user', 'content': '\\nclass Person:\\n    def __init__(self, name, surname, age):\\n        self.name = name\\n        self.surname = surname\\n        self.age = age\\n\\n    def info(self, additional=\"\"):\\n        print(\\'My name is :\\' + self.name + additional)\\n'}, {'role': 'assistant', 'content': 'A class to represent a person.\\n\\nAttributes:\\n    name : first name of the person\\n    surname : family name of the person\\n    age : age of the person\\n'}, {'role': 'user', 'content': '\\nclass Animal:\\n    def __init__(self, name, sound, num_legs=4):\\n        self.name = name\\n        self.sound = sound\\n        self.num_legs = num_legs\\n\\n    def says(self, sound=None):\\n        if self.sound is None and sound is None:\\n            raise NotImplementedError(\"Silent Animals are not supported!\")\\n\\n        out_sound = self.sound if sound is None else sound\\n        print(self.says_str.format(name=self.name, sound=out_sound))\\n'}, {'role': 'assistant', 'content': 'A class to represent an animal.\\n\\nAttributes:\\n    name : name of the animal\\n    sound : sound made by the animal\\n    num_legs : number of legs the animal has\\n'}]\n</code></pre> <pre><code>code = \"\"\"class Room:\n    length = 0.0\n    breadth = 0.0\n\n    def calculate_area(self):\n        print(\"Area of Room =\", self.length * self.breadth)\n\"\"\"\n\n\nmessages = DEFAULT_MESSAGE_TEMPLATE + [{\"role\": \"user\", \"content\": code}]\n\nresponse = _completions_with_backoff(\n    model=\"gpt-3.5-turbo\", messages=messages, temperature=0.2, stop=['\"\"\"'], n=1\n)\n\nprint(response[\"choices\"][0][\"message\"][\"content\"])\n</code></pre> <pre><code>A class to represent a room.\n\nAttributes:\n    length : length of the room\n    breadth : breadth of the room\n\nMethods:\n    calculate_area : calculates the area of the room and prints it.\n</code></pre> <pre><code>@contextmanager\ndef mock_openai_create():\n    mock_choices = {\n        \"choices\": [\n            {\n                \"message\": {\n                    \"content\": \"\"\"Drive a car\n\nArgs:\n    name: The name of the car\n    \"\"\"\n                }\n            }\n        ]\n    }\n    with unittest.mock.patch(\"openai.ChatCompletion\") as mock:\n        mock.create.return_value = mock_choices\n        yield\n</code></pre> <pre><code>with mock_openai_create():\n    response = openai.ChatCompletion.create()\n    print(response['choices'][0]['message']['content'])\n</code></pre> <pre><code>Drive a car\n\nArgs:\n    name: The name of the car\n</code></pre> <pre><code>@_retry_with_exponential_backoff()\ndef mock_func():\n    return \"Success\"\n\n\nassert mock_func() == \"Success\"\n\n\n# Test max retries exceeded\n@_retry_with_exponential_backoff(max_retries=1)\ndef mock_func_error():\n    raise openai.error.RateLimitError\n\n\nwith pytest.raises(Exception) as e:\n    mock_func_error()\n\nprint(e.value)\nassert str(e.value) == \"Maximum number of retries (1) exceeded.\"\n</code></pre> <pre><code>Note: OpenAI's API rate limit reached. Command will automatically retry in 3 seconds. For more information visit: https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits\nMaximum number of retries (1) exceeded.\n</code></pre> <pre><code>docstrings = [\n    \"    _check_and_add_docstrings_to_source(\\n    source: str, include_auto_gen_txt: bool, **kwargs\\n) -&gt; str:\\n    source = _remove_auto_generated_docstring(source)    \\n    tree = ast.parse(source)\\n    line_offset = 0\\n\\n    for node in tree.body:\\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\\n            continue\\n        \\n        if ast.get_docstring(node) is not None:\\n            continue\\n\\n        source, line_offset = _add_docstring(\\n            source, node, line_offset, include_auto_gen_txt, **kwargs\\n        )\\n        if not isinstance(node, ast.ClassDef):\\n            continue\\n        \",\n    '    _check_and_add_docstrings_to_source\\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n    This function checks if the source code has docstrings for all the functions and classes.\\n    If not, it adds a docstring to the function/class.\\n\\n    Args:\\n        source (str): The source code to be checked for docstrings.\\n        include_auto_gen_txt (bool): If True, the docstring will include the text \"Auto-generated by nbdev\".\\n        **kwargs: Additional keyword arguments.\\n\\n    Returns:\\n        str: The source code with docstrings added.\\n',\n    \"    This function checks if the source code has docstrings for all the functions and classes.\\n    If not, it adds the docstrings.\\n    It also removes the auto generated docstring.\\n    \\n    Args:\\n        source: The source code as a string.\\n        include_auto_gen_txt: Whether to include the auto generated text in the docstring.\\n        **kwargs: Other keyword arguments.\\n    \\n    Returns:\\n        The source code with docstrings added.\\n    \\n    Raises:\\n        ValueError: If the source code is not a string.\\n\",\n]\n\nactual = _get_best_docstring(docstrings)\nexpected = docstrings[2]\n\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>    This function checks if the source code has docstrings for all the functions and classes.\n    If not, it adds the docstrings.\n    It also removes the auto generated docstring.\n\n    Args:\n        source: The source code as a string.\n        include_auto_gen_txt: Whether to include the auto generated text in the docstring.\n        **kwargs: Other keyword arguments.\n\n    Returns:\n        The source code with docstrings added.\n\n    Raises:\n        ValueError: If the source code is not a string.\n</code></pre> <pre><code>docstrings = [\n    \"    _check_and_add_docstrings_to_source(\\n    source: str, include_auto_gen_txt: bool, **kwargs\\n) -&gt; str:\\n    source = _remove_auto_generated_docstring(source)    \\n    tree = ast.parse(source)\\n    line_offset = 0\\n\\n    for node in tree.body:\\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\\n            continue\\n        \\n        if ast.get_docstring(node) is not None:\\n            continue\\n\\n        source, line_offset = _add_docstring(\\n            source, node, line_offset, include_auto_gen_txt, **kwargs\\n        )\\n        if not isinstance(node, ast.ClassDef):\\n            continue\\n        \",\n    '    _check_and_add_docstrings_to_source\\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n    This function checks if the source code has docstrings for all the functions and classes.\\n    If not, it adds a docstring to the function/class.\\n\\n    Args:\\n        source (str): The source code to be checked for docstrings.\\n        include_auto_gen_txt (bool): If True, the docstring will include the text \"Auto-generated by nbdev\".\\n        **kwargs: Additional keyword arguments.\\n\\n    Returns:\\n        str: The source code with docstrings added.\\n',\n    \"    This function checks if the source code ~~~~~~~~~~~~~~~~ has docstrings for all the functions and classes.\\n    If not, it adds the docstrings.\\n    It also removes the auto generated docstring.\\n    \\n    Args:\\n        source: The source code as a string.\\n        include_auto_gen_txt: Whether to include the auto generated text in the docstring.\\n        **kwargs: Other keyword arguments.\\n    \\n    Returns:\\n        The source code with docstrings added.\\n    \\n    Raises:\\n        ValueError: If the source code is not a string.\\n\",\n]\n\nactual = _get_best_docstring(docstrings)\nexpected = None\n\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>None\n</code></pre> <pre><code>linenos = _get_classes_and_functions(source)\nclasses_and_functions = [\n    _get_code_from_source(source, start_line_no, end_line_no)\n    for start_line_no, docstring_line_no, end_line_no, node_offset in linenos\n]\nwith mock_openai_create():\n    for code in classes_and_functions:\n        docstring = _generate_docstring_using_chat_gpt(\n            code,\n            DEFAULT_MESSAGE_TEMPLATE,\n            model=\"gpt-3.5-turbo\",\n            temperature=0.2,\n            stop=['\"\"\"'],\n            n=3,\n        )\n\n        print(docstring)\n</code></pre> <pre><code>Drive a car\n\nArgs:\n    name: The name of the car\n\nDrive a car\n\nArgs:\n    name: The name of the car\n\nDrive a car\n\nArgs:\n    name: The name of the car\n\nDrive a car\n\nArgs:\n    name: The name of the car\n</code></pre> <pre><code>print(AUTO_GEN_TXT)\n</code></pre> <pre><code>!!! note\n\n    The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n</code></pre> <pre><code>docstring = \"\"\"Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n\"\"\"\n\nexpected = docstring + AUTO_GEN_TXT + \"\\n\"\n\nactual = _add_auto_gen_txt(docstring)\nprint(actual)\n\nassert actual == expected\n</code></pre> <pre><code>Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n\n!!! note\n\n    The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n</code></pre> <pre><code>docstring = \"\"\"Sample docstring\n\n    Args:\n        s: sample args\n\n    Returns:\n        sample return\n\"\"\"\n\nexpected_false = '''\"\"\"Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n\"\"\"'''\nexpected_true = (\n'''\"\"\"Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n'''\n    + AUTO_GEN_TXT\n    + '\\n\"\"\"'\n)\n\nfor col_offset in [0, 4, 8]:\n    for include_auto_gen_txt, expected in zip(\n        [False, True], [expected_false, expected_true]\n    ):\n        expected = textwrap.indent(expected, prefix=\" \" * col_offset)\n        actual = _fix_docstring_indent(\n            docstring, col_offset, include_auto_gen_txt=include_auto_gen_txt\n        )\n        print(actual)\n        assert actual == expected\n</code></pre> <pre><code>\"\"\"Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n\"\"\"\n\"\"\"Sample docstring\n\nArgs:\n    s: sample args\n\nReturns:\n    sample return\n\n!!! note\n\n    The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n\"\"\"\n    \"\"\"Sample docstring\n\n    Args:\n        s: sample args\n\n    Returns:\n        sample return\n    \"\"\"\n    \"\"\"Sample docstring\n\n    Args:\n        s: sample args\n\n    Returns:\n        sample return\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n        \"\"\"Sample docstring\n\n        Args:\n            s: sample args\n\n        Returns:\n            sample return\n        \"\"\"\n        \"\"\"Sample docstring\n\n        Args:\n            s: sample args\n\n        Returns:\n            sample return\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n</code></pre> <pre><code>linenos = _get_classes_and_functions(source)\nclasses_and_functions = [\n    _get_code_from_source(source, start_line_no, end_line_no)\n    for start_line_no, docstring_line_no, end_line_no, node_offset in linenos\n]\nprint(len(classes_and_functions))\n</code></pre> <pre><code>4\n</code></pre> <pre><code>line_offset = 0\nwith mock_openai_create():\n    docstrings = [\n        _generate_docstring_using_chat_gpt(\n            i,\n            DEFAULT_MESSAGE_TEMPLATE,\n            model=\"gpt-3.5-turbo\",\n            temperature=0.2,\n            stop=['\"\"\"'],\n            n=3,\n        )\n        for i in classes_and_functions\n    ]\n\n    print(docstrings)\n\nsource_lines = source.split(\"\\n\")\noffsets = [node_offset for i, _, _, node_offset in linenos]\n\nindented_docstrings = [\n    _fix_docstring_indent(docstring, offset, include_auto_gen_txt=include_auto_gen_txt)\n    for docstring, offset in zip(docstrings, offsets)\n]\nfor i in indented_docstrings:\n    print(\"*\" * 100)\n    print(i)\n</code></pre> <pre><code>['Drive a car\\n\\nArgs:\\n    name: The name of the car\\n    ', 'Drive a car\\n\\nArgs:\\n    name: The name of the car\\n    ', 'Drive a car\\n\\nArgs:\\n    name: The name of the car\\n    ', 'Drive a car\\n\\nArgs:\\n    name: The name of the car\\n    ']\n****************************************************************************************************\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n****************************************************************************************************\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n****************************************************************************************************\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n****************************************************************************************************\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n</code></pre> <pre><code>actual = _inject_docstring_to_source(source, indented_docstrings, linenos)\nprint(actual)\n\ndocstring = \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n\"\"\"\n\nassert docstring in actual\n</code></pre> <pre><code>class Test:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        self.a = a\n\n    async def drive(self):\n\n\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        print(f'The {self.model} is now driving.')\n\n    def func_with_docstring():\n        \"\"\" Sample docstring\"\"\"\n        pass\n\ndef _check_and_add_docstrings_to_source(\n    source: str, include_auto_gen_txt: bool, **kwargs\n) -&gt; str:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    source = _remove_auto_generated_docstring(source)    \n    tree = ast.parse(source)\n    line_offset = 0\n\n    for node in tree.body:\n        if not isinstance(node, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n            continue\n\n        if ast.get_docstring(node) is not None:\n            continue\n\n        source, line_offset = _add_docstring(\n            source, node, line_offset, include_auto_gen_txt, **kwargs\n        )\n        if not isinstance(node, ast.ClassDef):\n            continue\n        # Is a class and we need to check the functions inside\n        # 29 - 36 make it as a recursive function\n        for f in node.body:\n            if not isinstance(f, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                continue\n\n            if ast.get_docstring(f) is not None:\n                continue\n\n            # should be a function inside the class for which there is no docstring\n            source, line_offset = _add_docstring(\n                source, f, line_offset, include_auto_gen_txt, **kwargs\n            )\n\n    return source\n\ndef test_callback(tree, source, start_lineno, end_lineno):\n    \"\"\"Prints the source code of the given node\n\n    Args:\n        tree: The AST tree\n        source: The source code\n        start_lineno: The start line number\n        end_lineno: The end line number\n    \"\"\"\n\n    pass\n</code></pre> <pre><code>_source = (\n'''\ndef decorator1(func):\n    \"\"\"Decorator function that takes a function as an argument and returns a function.\"\"\"\n    pass\n\ndef decorator2(func):\n    \"\"\"Sample docstring\n\n    Args:\n        arg 1: arg 1 description\n        arg 2: arg 2 description\n\n    '''\n    + AUTO_GEN_TXT\n    + '''\n    \"\"\"\n    pass\n'''\n)\n\nexpected = '''\ndef decorator1(func):\n    \"\"\"Decorator function that takes a function as an argument and returns a function.\"\"\"\n    pass\n\ndef decorator2(func):\n    pass\n'''\n\nactual = _remove_auto_generated_docstring(_source)\nprint(actual)\n\nassert actual == expected\n</code></pre> <pre><code>def decorator1(func):\n    \"\"\"Decorator function that takes a function as an argument and returns a function.\"\"\"\n    pass\n\ndef decorator2(func):\n    pass\n</code></pre> <pre><code>nl = \"\\n\"\n_source = (\n\"\"\"\nclass Test:\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        self.a = a\n\ndef test_callback(tree, source, start_lineno, end_lineno):\n    \\\"\"\"Check and add docstrings to source\n\n    Args:\n        source: Source code\n        include_auto_gen_txt: Include auto gen text\n        recreate_auto_gen_docs: If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one.\n        kwargs: Keyword arguments\n\n    Returns:\n        The source code with docstrings\n\n\"\"\"\n    + f'{nl.join([textwrap.indent(l, \" \"*4) for l in AUTO_GEN_TXT.split(nl)])}'\n    + \"\"\"\n    \\\"\"\"\n\n    pass\n\n\"\"\"\n)\nwith mock_openai_create():\n    updated_source = _check_and_add_docstrings_to_source(\n        _source,\n        include_auto_gen_txt=True,\n        recreate_auto_gen_docs=True,\n        model=\"gpt-3.5-turbo\",\n        temperature=0.2,\n        stop=['\"\"\"'],\n    )\n\nast.parse(updated_source)\n\nassert \"Check and add docstrings to source\" not in updated_source\nprint(updated_source)\n</code></pre> <pre><code>class Test:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        self.a = a\n\ndef test_callback(tree, source, start_lineno, end_lineno):\n\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    pass\n</code></pre> <pre><code>with mock_openai_create():\n    updated_source = _check_and_add_docstrings_to_source(\n        _source,\n        include_auto_gen_txt=True,\n        recreate_auto_gen_docs=False,\n        model=\"gpt-3.5-turbo\",\n        temperature=0.2,\n        stop=['\"\"\"'],\n    )\n\nast.parse(updated_source)\n\nassert \"Check and add docstrings to source\" in updated_source\nprint(updated_source)\n</code></pre> <pre><code>class Test:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    CONST_VAL = 1\n\n    def __init__(self, a):\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        self.a = a\n\ndef test_callback(tree, source, start_lineno, end_lineno):\n    \"\"\"Check and add docstrings to source\n\n    Args:\n        source: Source code\n        include_auto_gen_txt: Include auto gen text\n        recreate_auto_gen_docs: If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one.\n        kwargs: Keyword arguments\n\n    Returns:\n        The source code with docstrings\n\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n\n    pass\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    nbs_path = Path(d) / \"nbs\"\n    nbs_path.mkdir(parents=True)\n\n    hidden_dir = nbs_path / \".hidden\"\n    hidden_dir.mkdir(parents=True)\n\n    shutil.copyfile(Path(\"..\") / \"settings.ini\", nbs_path / \"settings.ini\")\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", nbs_path / \"_test.ipynb\"\n    )\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", nbs_path / \"test.ipynb\"\n    )\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", nbs_path / \"test_1.ipynb\"\n    )\n\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", hidden_dir / \"test.ipynb\"\n    )\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", hidden_dir / \"test_1.ipynb\"\n    )\n\n    for f in nbs_path.rglob(\"*\"):\n        print(f)\n\n    files = _get_files(nbs_path)\n\n    assert len(files) == 2\n    print(f\"\\n\\n{files}\")\n    assert sorted(files) == sorted([nbs_path / \"test_1.ipynb\", nbs_path / \"test.ipynb\"]), files\n</code></pre> <pre><code>/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/.hidden\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/test_1.ipynb\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/settings.ini\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/test.ipynb\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/_test.ipynb\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/.hidden/test_1.ipynb\n/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/.hidden/test.ipynb\n\n\n[PosixPath('/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/test_1.ipynb'), PosixPath('/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmps_19y7i1/nbs/test.ipynb')]\n</code></pre> <pre><code>with pytest.raises(ValueError) as e:\n    with TemporaryDirectory() as d:\n        nbs_path = Path(d) / \"nbs\"\n        nbs_path.mkdir(parents=True)\n\n        _get_files(nbs_path)\n\nprint(e.value)\n</code></pre> <pre><code>The directory /private/var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmp8t12t08s/nbs does not contain any Python files or notebooks\n</code></pre> <p>source</p>"},{"location":"Docstring_Generator/#add_docstring_to_source","title":"add_docstring_to_source","text":"<pre><code> add_docstring_to_source (path:Union[str,pathlib.Path],\n                          include_auto_gen_txt:bool=True,\n                          recreate_auto_gen_docs:bool=False,\n                          model:str='gpt-3.5-turbo',\n                          temperature:float=0.2, max_tokens:int=250,\n                          top_p:float=1.0, n:int=3)\n</code></pre> <p>Reads a Jupyter notebook or Python file, or a directory containing these files, and adds docstrings to classes and methods that do not have them.</p> <p>Args: path: The path to the Jupyter notebook or Python file, or a directory containing these files. include_auto_gen_txt: If set to True, a note indicating that the docstring was autogenerated by docstring-gen library will be added to the end. recreate_auto_gen_docs: If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one. model: The name of the Codex model that will be used to generate docstrings. temperature: Setting the temperature close to zero produces better results, whereas higher temperatures produce more complex, and sometimes irrelevant docstrings. max_tokens: The maximum number of tokens to be used when generating a docstring for a function or class. Please note that a higher number will deplete your token quota faster. top_p: You can also specify a top-P value from 0-1 to achieve similar results to changing the temperature. According to the Open AI documentation, it is generally recommended to change either this or the temperature but not both. n: The number of docstrings to be generated for each function or class, with the best one being added to the source code. Please note that a higher number will deplete your token quota faster.</p> <p>Returns: None</p> <p>Note</p> <p>The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)</p> <pre><code>with TemporaryDirectory() as d:\n    nbs_path = Path(d) / \"nbs\"\n    nbs_path.mkdir(parents=True)\n\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", nbs_path / \"test.ipynb\"\n    )\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"Test_Data.ipynb\", nbs_path / \"_test.ipynb\"\n    )\n\n    shutil.copyfile(Path(\"..\") / \"fixtures\" / \"test_data.py\", nbs_path / \"test_data.py\")\n    shutil.copyfile(\n        Path(\"..\") / \"fixtures\" / \"invalid_test_data.py\",\n        nbs_path / \"invalid_test_data.py\",\n    )\n    shutil.copyfile(Path(\"..\") / \"settings.ini\", nbs_path / \"settings.ini\")\n\n    with mock_openai_create():\n        add_docstring_to_source(nbs_path, recreate_auto_gen_docs=True)\n\n    with (nbs_path / \"test.ipynb\").open(\"r\") as f:\n        nb = nbformat.read(f, as_version=4)\n\nfor cell in nb.cells:\n    if cell.cell_type == \"code\":\n        print(cell[\"source\"])\n</code></pre> <pre><code>WARNING: Unable to parse the /var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmpxlv2_fom/nbs/invalid_test_data.py due to: invalid syntax (&lt;unknown&gt;, line 4). Skipping the file for docstring generation.\nSuccessfully added docstrings to /var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmpxlv2_fom/nbs/test_data.py\nWARNING: Unable to parse the below cell contents in /var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmpxlv2_fom/nbs/test.ipynb due to: invalid syntax (&lt;unknown&gt;, line 2). Skipping the cell for docstring generation.\nwith TemporaryDirectory() as d:\n    !ls -la {d}\nSuccessfully added docstrings to /var/folders/6n/3rjds7v52cd83wqkd565db0h0000gn/T/tmpxlv2_fom/nbs/test.ipynb\n# | export\n\nfrom typing import *\nimport os\nfrom pathlib import Path\n# from contextlib import contextmanager\n\nfrom contextlib import contextmanager\n\nimport shutil\nfrom tempfile import TemporaryDirectory\n\n_source = '''\ndef decorator1(func):\n    \"\"\"Decorator function that takes a function as an argument and returns a function.\"\"\"\n    pass\n\ndef decorator2(func):\n    pass\n'''\n\nwith TemporaryDirectory() as d:\n    !ls -la {d}\n# | export\n\n# Vehicle class\nclass Vehicle:\n    # Constructor function\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    def __init__(self, brand, model, type):\n        \"\"\"Constructor function\n\n        Args:\n            brand: Vehicle's brand\n            model: Vehicle's model\n            type: Vehicle's type\n        \"\"\"\n        self.brand = brand\n        self.model = model\n        self.type = type\n        self.gas_tank_size = 14\n        self.fuel_level = 0\n\n    # fuel_up function\n    def fuel_up(self):\n        # comment goes here\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        self.fuel_level = self.gas_tank_size\n        return 'Gas tank is now full.'\n\n    # drive function\n    async def drive(self):\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        print(f'The {self.model} is now driving.')\nv = Vehicle(\"honda\", \"city\", \"hatchback\")\nactual = v.fuel_up()\n\nprint(actual)\nassert actual == 'Gas tank is now full.'\ndef say_hello(name: str) -&gt; str:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    return f\"Hello, {name}\"\n\nasync def function_with_docstring(name: str) -&gt; str:\n    \"\"\" This function already has docstring\"\"\"\n    return f\"I won't say hello, {name}\"\n\nasync def dont_say_hello(name: str) -&gt; str:\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    return f\"I won't say hello, {name}\"\n\ndef decorator1(func):\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    def inner():\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        func()\n    return inner\n\ndef decorator2(func):\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    def inner():\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        func()\n    return inner\n\n@decorator1\n@decorator2\ndef outer_func():\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    def inner_func():\n        \"\"\"Drive a car\n\n        Args:\n            name: The name of the car\n\n        !!! note\n\n            The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n        \"\"\"\n        print(\"Hello, World!\")\n    inner_func()\n@contextmanager\ndef my_context_mgr():\n    \"\"\"Drive a car\n\n    Args:\n        name: The name of the car\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    try:\n        yield\n    finally:\n        pass\n</code></pre>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>docstring-gen</li> <li>API<ul> <li>docstring_gen<ul> <li>docstring_generator<ul> <li>add_docstring_to_source</li> </ul> </li> </ul> </li> </ul> </li> <li>CLI<ul> <li>docstring_gen</li> </ul> </li> <li>Releases</li> </ul>"},{"location":"api/docstring_gen/docstring_generator/add_docstring_to_source/","title":"add_docstring_to_source","text":""},{"location":"api/docstring_gen/docstring_generator/add_docstring_to_source/#docstring_gen.docstring_generator.add_docstring_to_source","title":"<code>docstring_gen.docstring_generator.add_docstring_to_source(path: Union[str, Path], include_auto_gen_txt: bool = True, recreate_auto_gen_docs: bool = False, model: str = 'gpt-3.5-turbo', temperature: float = 0.2, max_tokens: int = 250, top_p: float = 1.0, n: int = 3) -&gt; None</code>","text":"<p>Reads a Jupyter notebook or Python file, or a directory containing these files, and adds docstrings to classes and methods that do not have them.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>The path to the Jupyter notebook or Python file, or a directory containing these files.</p> required <code>include_auto_gen_txt</code> <code>bool</code> <p>If set to True, a note indicating that the docstring was autogenerated by docstring-gen library will be added to the end.</p> <code>True</code> <code>recreate_auto_gen_docs</code> <code>bool</code> <p>If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one.</p> <code>False</code> <code>model</code> <code>str</code> <p>The name of the Codex model that will be used to generate docstrings.</p> <code>'gpt-3.5-turbo'</code> <code>temperature</code> <code>float</code> <p>Setting the temperature close to zero produces better results, whereas higher temperatures produce more complex, and sometimes irrelevant docstrings.</p> <code>0.2</code> <code>max_tokens</code> <code>int</code> <p>The maximum number of tokens to be used when generating a docstring for a function or class. Please note that a higher number will deplete your token quota faster.</p> <code>250</code> <code>top_p</code> <code>float</code> <p>You can also specify a top-P value from 0-1 to achieve similar results to changing the temperature. According to the Open AI documentation, it is generally recommended to change either this or the temperature but not both.</p> <code>1.0</code> <code>n</code> <code>int</code> <p>The number of docstrings to be generated for each function or class, with the best one being added to the source code. Please note that a higher number will deplete your token quota faster.</p> <code>3</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Note</p> <p>The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)</p> Source code in <code>docstring_gen/docstring_generator.py</code> <pre><code>def add_docstring_to_source(\n    path: Union[str, Path],\n    include_auto_gen_txt: bool = True,\n    recreate_auto_gen_docs: bool = False,\n    model: str = \"gpt-3.5-turbo\",\n    temperature: float = 0.2,\n    max_tokens: int = 250,\n    top_p: float = 1.0,\n    n: int = 3,\n) -&gt; None:\n\"\"\"Reads a Jupyter notebook or Python file, or a directory containing these files, and adds docstrings to classes and methods that do not have them.\n\n    Args:\n        path: The path to the Jupyter notebook or Python file, or a directory containing these files.\n        include_auto_gen_txt: If set to True, a note indicating that the docstring was autogenerated by docstring-gen library will be added to the end.\n        recreate_auto_gen_docs: If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one.\n        model: The name of the Codex model that will be used to generate docstrings.\n        temperature: Setting the temperature close to zero produces better results, whereas higher temperatures produce more complex, and sometimes irrelevant docstrings.\n        max_tokens: The maximum number of tokens to be used when generating a docstring for a function or class. Please note that a higher number will deplete your token quota faster.\n        top_p: You can also specify a top-P value from 0-1 to achieve similar results to changing the temperature. According to the Open AI documentation, it is generally recommended to change either this or the temperature but not both.\n        n: The number of docstrings to be generated for each function or class, with the best one being added to the source code. Please note that a higher number will deplete your token quota faster.\n\n    Returns:\n        None\n\n    !!! note\n\n        The above docstring is autogenerated by docstring-gen library (https://docstring-gen.airt.ai)\n    \"\"\"\n    path = Path(path)\n    files = _get_files(path) if path.is_dir() else [path]\n    frequency_penalty = 0.0\n    presence_penalty = 0.0\n    stop = ['\"\"\"']\n\n    for file in files:\n        if file.suffix == \".ipynb\":\n            _add_docstring_to_nb(\n                file=file,\n                include_auto_gen_txt=include_auto_gen_txt,\n                recreate_auto_gen_docs=recreate_auto_gen_docs,\n                model=model,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=top_p,\n                frequency_penalty=frequency_penalty,\n                presence_penalty=presence_penalty,\n                stop=stop,\n                n=n,\n            )\n        else:\n            _add_docstring_to_py(\n                file=file,\n                include_auto_gen_txt=include_auto_gen_txt,\n                recreate_auto_gen_docs=recreate_auto_gen_docs,\n                model=model,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                top_p=top_p,\n                frequency_penalty=frequency_penalty,\n                presence_penalty=presence_penalty,\n                stop=stop,\n                n=n,\n            )\n</code></pre>"},{"location":"cli/docstring_gen/","title":"<code>docstring_gen</code>","text":"<p>This command reads a Jupyter notebook or Python file, or a directory containing these files, and adds docstrings to classes and methods that do not have them.</p> <p>Usage:</p> <pre><code>$ docstring_gen [OPTIONS] [PATH]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PATH]</code>: The path to the Jupyter notebook or Python file, or a directory containing these files  [default: .]</li> </ul> <p>Options:</p> <ul> <li><code>--include-auto-gen-txt / --no-include-auto-gen-txt</code>: If set to True, a note indicating that the docstring was autogenerated by docstring-gen library will be added to the end.  [default: include-auto-gen-txt]</li> <li><code>-f, --force-recreate-auto-generated</code>: If set to True, the autogenerated docstrings from the previous runs will be replaced with the new one.</li> <li><code>--model TEXT</code>: The name of the GPT model that will be used to generate docstrings.  [default: gpt-3.5-turbo]</li> <li><code>--temperature FLOAT RANGE</code>: Setting the temperature close to zero produces better results, whereas higher temperatures produce more complex, and sometimes irrelevant docstrings.  [default: 0.2; 0.0&lt;=x&lt;=2.0]</li> <li><code>--max-tokens INTEGER</code>: The maximum number of tokens to be used when generating a docstring for a function or class. Please note that a higher number will deplete your token quota faster.  [default: 250]</li> <li><code>--top-p FLOAT RANGE</code>: You can also specify a top-P value from 0-1 to achieve similar results to changing the temperature. According to the Open AI documentation, it is generally recommended to change either this or the temperature but not both.  [default: 1.0; 0.0&lt;=x&lt;=1.0]</li> <li><code>--n INTEGER</code>: The number of docstrings to be generated for each function or class, with the best one being added to the source code. Please note that a higher number will deplete your token quota faster.  [default: 3]</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"}]}